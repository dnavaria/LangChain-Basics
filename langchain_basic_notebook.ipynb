{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libs\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompts and LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If we don't specify the model, it will default to text-davinci-003 OPENAI model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Temperature is a parameter of llms that determines the randomness and hence the creativity of the response.\n",
    "- Its value can be between 0 and 1\n",
    "  - `0` implies deterministic responses where you are likely to see the exact same response generated every time you run the prompt.\n",
    "  - `1` gives you a highly variable and creative response.\n",
    "- If you want different response generated each time, set the temperature to be `1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response :: \n",
      "Output:\n",
      "{\n",
      "  \"Full Name\": \"Patrick Quinn\",\n",
      "  \"Title\": \"Architecture Manager\",\n",
      "  \"Certification\": \"RA, LEED AP, WELL AP\",\n",
      "  \"Phone Number\": null,\n",
      "  \"Email ID\": null,\n",
      "  \"BIO\": null\n",
      "}\n",
      "Detected Response :: {'Full Name': 'Patrick Quinn', 'Title': 'Architecture Manager', 'Certification': 'RA, LEED AP, WELL AP', 'Phone Number': None, 'Email ID': None, 'BIO': None}\n"
     ]
    }
   ],
   "source": [
    "prompt = '''read html that i will provide in next line text given below and extract employee / person information such as Full Name, Title, Certification, Phone Number, Email ID, BIO. Use these as keys for json Full Name, Title, Certification, Phone Number, Email ID, BIO and return output as json format. If some information not present then just return null as value for that key, I only want json not a string.\n",
    "HTML DOCUMENT = \"\"\"<html> <body><div class=\"\"fl-mosaicflow-item\"\" id=\"\"mosaic-0-itemid-22\"\" style=\"\"; color: rgb(28, 22, 74); display: block; font-family: Lato; font-size: 20px; font-style: normal; font-weight: 400\"\"> <div class=\"\"fl-photo fl-photo-align-center\"\" itemscope=\"\"\"\" itemtype=\"\"https://schema.org/ImageObject\"\" style=\"\"; color: rgb(28, 22, 74); display: block; font-family: Lato; font-size: 20px; font-style: normal; font-weight: 400\"\"> <div class=\"\"fl-photo-content fl-photo-img-jpg\"\" style=\"\"; color: rgb(28, 22, 74); display: inline-block; font-family: Lato; font-size: 20px; font-style: normal; font-weight: 400\"\"> <div class=\"\"fl-photo-caption fl-photo-caption-hover\"\" itemprop=\"\"caption\"\" style=\"\"; color: rgb(255, 255, 255); display: block; font-family: Lato; font-size: 13px; font-style: normal; font-weight: 400\"\"> Patrick Quinn, RA, LEED AP, WELL AP, Architecture Manager </div> </div> </div> </div> </body> </html>\"\"\"\n",
    "'''\n",
    "\n",
    "response = llm(prompt=prompt)\n",
    "print(f\"Response :: {response}\")\n",
    "\n",
    "detected_response = json.loads(\"\".join(response.split('\\n')[2:]))\n",
    "print(f\"Detected Response :: {detected_response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_2 = \"What would be a good company name for an enterprise that makes colorful socks?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = llm.generate(prompts=[prompt_2]*5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HappySox\n",
      "Gleaming Toes Socks Co.\n",
      "Colorful Sock Studio\n",
      "Rainbow Sockery\n",
      "Socktivity.\n"
     ]
    }
   ],
   "source": [
    "for cname in response_2.generations:\n",
    "    print(cname[0].text.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
